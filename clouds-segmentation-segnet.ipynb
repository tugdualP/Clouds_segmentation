{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install --upgrade imgaug","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:12:18.336071Z","iopub.status.busy":"2021-11-24T08:12:18.335711Z","iopub.status.idle":"2021-11-24T08:12:25.205832Z","shell.execute_reply":"2021-11-24T08:12:25.204960Z","shell.execute_reply.started":"2021-11-24T08:12:18.336015Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importation des modules utiles","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport albumentations as albu\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport colorama\nfrom colorama import Fore\nfrom imgaug.augmentables.segmaps import SegmentationMapOnImage\n\nfrom tensorflow.keras.optimizers import Nadam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import Sequence","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:12:32.950706Z","iopub.status.busy":"2021-11-24T08:12:32.950389Z","iopub.status.idle":"2021-11-24T08:12:36.440565Z","shell.execute_reply":"2021-11-24T08:12:36.438893Z","shell.execute_reply.started":"2021-11-24T08:12:32.950649Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import des scripts de fonctions utiles","metadata":{}},{"cell_type":"code","source":"from clouds_graph_functions import visualize_image_mask_prediction\nfrom clouds_utilities_functions import np_resize, build_masks\nfrom clouds_utilities_functions import dice_coef, dice_loss, bce_dice_loss, dice_coef_class","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:12:45.131353Z","iopub.status.busy":"2021-11-24T08:12:45.131018Z","iopub.status.idle":"2021-11-24T08:12:45.251436Z","shell.execute_reply":"2021-11-24T08:12:45.250775Z","shell.execute_reply.started":"2021-11-24T08:12:45.131301Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Définition du chemin des données","metadata":{}},{"cell_type":"code","source":"NUAGES_PATH = '/kaggle/input/understanding_cloud_organization/'\n\nNUAGES_TRAIN_PATH = NUAGES_PATH + 'train_images/'","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:12:49.711056Z","iopub.status.busy":"2021-11-24T08:12:49.710724Z","iopub.status.idle":"2021-11-24T08:12:49.717031Z","shell.execute_reply":"2021-11-24T08:12:49.713969Z","shell.execute_reply.started":"2021-11-24T08:12:49.711004Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chargement du DataFrame et modification pour le DataGenerator","metadata":{}},{"cell_type":"code","source":"# Chargement du jeu de données d'entrainement\ntrain_df = pd.read_csv(NUAGES_PATH + 'train.csv')","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:12:52.391557Z","iopub.status.busy":"2021-11-24T08:12:52.391264Z","iopub.status.idle":"2021-11-24T08:13:00.563850Z","shell.execute_reply":"2021-11-24T08:13:00.563121Z","shell.execute_reply.started":"2021-11-24T08:12:52.391509Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:02.908811Z","iopub.status.busy":"2021-11-24T08:13:02.908445Z","iopub.status.idle":"2021-11-24T08:13:02.948757Z","shell.execute_reply":"2021-11-24T08:13:02.948021Z","shell.execute_reply.started":"2021-11-24T08:13:02.908731Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:04.993949Z","iopub.status.busy":"2021-11-24T08:13:04.993638Z","iopub.status.idle":"2021-11-24T08:13:05.021081Z","shell.execute_reply":"2021-11-24T08:13:05.020190Z","shell.execute_reply.started":"2021-11-24T08:13:04.993897Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:08.168913Z","iopub.status.busy":"2021-11-24T08:13:08.168609Z","iopub.status.idle":"2021-11-24T08:13:08.200311Z","shell.execute_reply":"2021-11-24T08:13:08.199577Z","shell.execute_reply.started":"2021-11-24T08:13:08.168863Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mask_count_df.shape)\nmask_count_df.head()","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:10.262527Z","iopub.status.busy":"2021-11-24T08:13:10.262222Z","iopub.status.idle":"2021-11-24T08:13:10.273507Z","shell.execute_reply":"2021-11-24T08:13:10.272361Z","shell.execute_reply.started":"2021-11-24T08:13:10.262477Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parametres generaux","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 6\nHEIGHT = 320\nWIDTH = 480\nCHANNELS = 3 # toujours garder 3 channels car les modèles d'initialisation des poids ont été entrainé sur des images couleurs avec 3 canaux\nCOLOR_MODE=True # True pour images couleurs et False pour images en noir et blanc\nNB_CLASSES = 4","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:13.544077Z","iopub.status.busy":"2021-11-24T08:13:13.543745Z","iopub.status.idle":"2021-11-24T08:13:13.549228Z","shell.execute_reply":"2021-11-24T08:13:13.548252Z","shell.execute_reply.started":"2021-11-24T08:13:13.544019Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator pour image et masque","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=NUAGES_TRAIN_PATH, batch_size=BATCH_SIZE, dim=(1400, 2100),\n                 n_channels=CHANNELS, color_mode=True, reshape=None, augment=False,\n                 n_classes=NB_CLASSES, random_state=222, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.reshape = reshape\n        self.n_channels = n_channels\n        self.color_mode = color_mode\n        self.augment = augment\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n        np.random.seed(self.random_state)\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            \n            if self.augment:\n                X, y = self.__augment_batch(X, y)\n            \n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)          \n\n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        if self.reshape is None:\n            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        else:\n            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}{im_name}\"\n            \n            if self.color_mode == True:\n                img = self.__load_rgb(img_path)\n                \n                if self.reshape is not None:\n                    img = np_resize(img, self.reshape)\n            \n            else:\n                img = self.__load_grayscale(img_path)\n                \n                if self.reshape is not None:\n                    img = np_resize(img, self.reshape)\n                \n                img = np.dstack((img,)*self.n_channels) # stack the black and white image in n channels\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n\n    def __generate_y(self, list_IDs_batch):\n        if self.reshape is None:\n            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        else:\n            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            \n            if self.reshape is not None:\n                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n            else:\n                masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n        return img\n    \n    def __random_transform(self, img, masks):\n        #augmentation random d'images\n        composition = albu.Compose([albu.HorizontalFlip(),\n                                    albu.VerticalFlip(),\n                                    albu.Rotate(limit=20),\n                                    albu.GridDistortion(),\n                                    albu.ShiftScaleRotate(rotate_limit=45, shift_limit=0.15, scale_limit=0.15)])\n        \n        composed = composition(image=img, mask=masks)\n        aug_img = composed['image']\n        aug_masks = composed['mask']\n        \n        return aug_img, aug_masks  \n    \n    def __augment_batch(self, img_batch, masks_batch):\n        # generation du batch d'augmentation de l'image et de son masque associé\n        for i in range(img_batch.shape[0]):\n            img_batch[i, ], masks_batch[i, ] = self.__random_transform(img_batch[i, ], masks_batch[i, ])\n        \n        return img_batch, masks_batch","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:44.114289Z","iopub.status.busy":"2021-11-24T08:13:44.113976Z","iopub.status.idle":"2021-11-24T08:13:44.146991Z","shell.execute_reply":"2021-11-24T08:13:44.145884Z","shell.execute_reply.started":"2021-11-24T08:13:44.114236Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Séparation des données d'entrainement et de validation (par ID unique)","metadata":{}},{"cell_type":"code","source":"train_idx, val_idx = train_test_split(mask_count_df.index, random_state=69, test_size=0.2)","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:50.756180Z","iopub.status.busy":"2021-11-24T08:13:50.755872Z","iopub.status.idle":"2021-11-24T08:13:50.762983Z","shell.execute_reply":"2021-11-24T08:13:50.762178Z","shell.execute_reply.started":"2021-11-24T08:13:50.756128Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Création des instances de la class DataGenerator","metadata":{}},{"cell_type":"code","source":"train_generator = DataGenerator(train_idx, \n                                df=mask_count_df,\n                                target_df=train_df,\n                                batch_size=BATCH_SIZE,\n                                reshape=(HEIGHT, WIDTH),\n                                augment=True,\n                                n_channels=CHANNELS,\n                                color_mode = COLOR_MODE,\n                                n_classes=NB_CLASSES)\n\nvalid_generator = DataGenerator(val_idx, \n                                  df=mask_count_df,\n                                  target_df=train_df,\n                                  batch_size=BATCH_SIZE, \n                                  reshape=(HEIGHT, WIDTH),\n                                  augment=False,\n                                  n_channels=CHANNELS,\n                                  color_mode = COLOR_MODE,\n                                  n_classes=NB_CLASSES)","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:53.505701Z","iopub.status.busy":"2021-11-24T08:13:53.505393Z","iopub.status.idle":"2021-11-24T08:13:53.512576Z","shell.execute_reply":"2021-11-24T08:13:53.511314Z","shell.execute_reply.started":"2021-11-24T08:13:53.505647Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"# ModelCheckpoint callback : pour enregistrer les poids du modele.\ncheckpoint = ModelCheckpoint(\"./model.h5\",\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             save_weights_only=True)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               mode='min',\n                               min_delta = 0.01,\n                               patience=5,\n                               restore_best_weights=True,\n                               verbose=1)\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n                                         mode='min',\n                                         episilon = 0.01,\n                                         patience=3,\n                                         factor=0.1,\n                                         min_lr=1e-6,\n                                         verbose=1)\n\n# CSVLogger callback : pour enregistrer l'historique d'entrainement.\ncsv_logger = CSVLogger('./training.log')","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:13:56.476784Z","iopub.status.busy":"2021-11-24T08:13:56.476468Z","iopub.status.idle":"2021-11-24T08:13:56.483324Z","shell.execute_reply":"2021-11-24T08:13:56.482557Z","shell.execute_reply.started":"2021-11-24T08:13:56.476730Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MODELE de segmentation","metadata":{}},{"cell_type":"code","source":"#creation d'un modéle SEGNET avec un backbone VGG16 from scratch\n#Step #1: Creation des class MaxPoolingWithArgmax2D ( pour l'encoder) et MaxUnpooling2D ( pour le decoder)\n\nfrom keras import backend as K\nfrom keras.layers import Layer\nimport tensorflow as tf\n\n\nclass MaxPoolingWithArgmax2D(Layer):\n    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n        self.padding = padding\n        self.pool_size = pool_size\n        self.strides = strides\n\n    def call(self, inputs, **kwargs):\n        padding = self.padding\n        pool_size = self.pool_size\n        strides = self.strides\n        if K.backend() == \"tensorflow\":\n            ksize = [1, pool_size[0], pool_size[1], 1]\n            padding = padding.upper()\n            strides = [1, strides[0], strides[1], 1]\n            output, argmax =tf.nn.max_pool_with_argmax(\n                inputs, ksize=ksize, strides=strides, padding=padding\n            )\n        else:\n            errmsg = \"{} backend is not supported for layer {}\".format(\n                K.backend(), type(self).__name__\n            )\n            raise NotImplementedError(errmsg)\n        argmax = K.cast(argmax, K.floatx())\n        return [output, argmax]\n\n    def compute_output_shape(self, input_shape):\n        ratio = (1, 2, 2, 1)\n        output_shape = [\n            dim // ratio[idx] if dim is not None else None\n            for idx, dim in enumerate(input_shape)\n        ]\n        output_shape = tuple(output_shape)\n        return [output_shape, output_shape]\n\n    def compute_mask(self, inputs, mask=None):\n        return 2 * [None]\n\n\nclass MaxUnpooling2D(Layer):\n    def __init__(self, size=(2, 2), **kwargs):\n        super(MaxUnpooling2D, self).__init__(**kwargs)\n        self.size = size\n\n    def call(self, inputs, output_shape=None):\n        updates, mask = inputs[0], inputs[1]\n        with tf.variable_scope(self.name):\n            mask = K.cast(mask, \"int32\")\n            input_shape = tf.shape(updates, out_type=\"int32\")\n            #  calculation new shape\n            if output_shape is None:\n                output_shape = (\n                    input_shape[0],\n                    input_shape[1] * self.size[0],\n                    input_shape[2] * self.size[1],\n                    input_shape[3],\n                )\n            self.output_shape1 = output_shape\n\n            # calculation indices for batch, height, width and feature maps\n            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n            batch_range = K.reshape(\n                tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n            )\n            b = one_like_mask * batch_range\n            y = mask // (output_shape[2] * output_shape[3])\n            x = (mask // output_shape[3]) % output_shape[2]\n            feature_range = tf.range(output_shape[3], dtype=\"int32\")\n            f = one_like_mask * feature_range\n\n            # transpose indices & reshape update values to one dimension\n            updates_size = tf.size(updates)\n            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n            values = K.reshape(updates, [updates_size])\n            ret = tf.scatter_nd(indices, values, output_shape)\n            return ret\n\n    def compute_output_shape(self, input_shape):\n        mask_shape = input_shape[1]\n        return (\n            mask_shape[0],\n            mask_shape[1] * self.size[0],\n            mask_shape[2] * self.size[1],\n            mask_shape[3],\n        )","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:16:51.187804Z","iopub.status.busy":"2021-11-24T08:16:51.187501Z","iopub.status.idle":"2021-11-24T08:16:51.212126Z","shell.execute_reply":"2021-11-24T08:16:51.211257Z","shell.execute_reply.started":"2021-11-24T08:16:51.187741Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creation d'un modéle SEGNET avec un backbone VGG16\n#Step #2: Creation du modéle : encoder + decoder\n\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.core import Activation, Reshape\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\nfrom keras import layers\nimport keras\nimport urllib.request\n\n\ndef segnet(input_shape, n_labels, kernel=3, pool_size=(2, 2), output_mode=\"sigmoid\"):\n    # encoder\n    inputs = Input(shape=input_shape)\n\n    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n    conv_1 = BatchNormalization()(conv_1)\n    conv_1 = Activation(\"relu\")(conv_1)\n    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n    conv_2 = BatchNormalization()(conv_2)\n    conv_2 = Activation(\"relu\")(conv_2)\n\n    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n\n    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n    conv_3 = BatchNormalization()(conv_3)\n    conv_3 = Activation(\"relu\")(conv_3)\n    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n    conv_4 = BatchNormalization()(conv_4)\n    conv_4 = Activation(\"relu\")(conv_4)\n\n    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n\n    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n    conv_5 = BatchNormalization()(conv_5)\n    conv_5 = Activation(\"relu\")(conv_5)\n    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n    conv_6 = BatchNormalization()(conv_6)\n    conv_6 = Activation(\"relu\")(conv_6)\n    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n    conv_7 = BatchNormalization()(conv_7)\n    conv_7 = Activation(\"relu\")(conv_7)\n\n    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n\n    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n    conv_8 = BatchNormalization()(conv_8)\n    conv_8 = Activation(\"relu\")(conv_8)\n    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n    conv_9 = BatchNormalization()(conv_9)\n    conv_9 = Activation(\"relu\")(conv_9)\n    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n    conv_10 = BatchNormalization()(conv_10)\n    conv_10 = Activation(\"relu\")(conv_10)\n\n    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n\n    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n    conv_11 = BatchNormalization()(conv_11)\n    conv_11 = Activation(\"relu\")(conv_11)\n    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n    conv_12 = BatchNormalization()(conv_12)\n    conv_12 = Activation(\"relu\")(conv_12)\n    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n    conv_13 = BatchNormalization()(conv_13)\n    conv_13 = Activation(\"relu\")(conv_13)\n\n    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n    print(\"Build enceder done..\")    \n\n    # decoder\n\n    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n\n    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n    conv_14 = BatchNormalization()(conv_14)\n    conv_14 = Activation(\"relu\")(conv_14)\n    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n    conv_15 = BatchNormalization()(conv_15)\n    conv_15 = Activation(\"relu\")(conv_15)\n    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n    conv_16 = BatchNormalization()(conv_16)\n    conv_16 = Activation(\"relu\")(conv_16)\n\n    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n\n    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n    conv_17 = BatchNormalization()(conv_17)\n    conv_17 = Activation(\"relu\")(conv_17)\n    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n    conv_18 = BatchNormalization()(conv_18)\n    conv_18 = Activation(\"relu\")(conv_18)\n    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n    conv_19 = BatchNormalization()(conv_19)\n    conv_19 = Activation(\"relu\")(conv_19)\n\n    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n\n    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n    conv_20 = BatchNormalization()(conv_20)\n    conv_20 = Activation(\"relu\")(conv_20)\n    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n    conv_21 = BatchNormalization()(conv_21)\n    conv_21 = Activation(\"relu\")(conv_21)\n    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n    conv_22 = BatchNormalization()(conv_22)\n    conv_22 = Activation(\"relu\")(conv_22)\n\n    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n\n    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n    conv_23 = BatchNormalization()(conv_23)\n    conv_23 = Activation(\"relu\")(conv_23)\n    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n    conv_24 = BatchNormalization()(conv_24)\n    conv_24 = Activation(\"relu\")(conv_24)\n\n    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n\n    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n    conv_25 = BatchNormalization()(conv_25)\n    conv_25 = Activation(\"relu\")(conv_25)\n\n    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n\n    outputs = Activation(\"sigmoid\")(conv_26)\n    print(\"Build decoder done..\")\n    \n    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n    \n    #chargement du modele VGG16 pré-entrainé  \n    pretrained_url = \"https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n    VGG_Weights_path = keras.utils.get_file(pretrained_url.split(\"/\")[-1], pretrained_url)\n    \n    model.load_weights(VGG_Weights_path, by_name=True, skip_mismatch=True)\n  \n\n    return model","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:16:54.405734Z","iopub.status.busy":"2021-11-24T08:16:54.405419Z","iopub.status.idle":"2021-11-24T08:16:54.445487Z","shell.execute_reply":"2021-11-24T08:16:54.444518Z","shell.execute_reply.started":"2021-11-24T08:16:54.405680Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Chargement des poids du modèle pré entrainé si existant","metadata":{}},{"cell_type":"code","source":"input_model_path = \"/kaggle/input/clouds-segmentation-segnet/model.h5\"\n\ntry:\n    model.load_weights(input_model_path)\n    print(\"model.h5 pré entrainé chargé!\")\nexcept:\n    print(\"model.h5 non pré entrainé, non chargé\")\n    pass","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:18:07.451750Z","iopub.status.busy":"2021-11-24T08:18:07.451432Z","iopub.status.idle":"2021-11-24T08:18:07.459233Z","shell.execute_reply":"2021-11-24T08:18:07.458474Z","shell.execute_reply.started":"2021-11-24T08:18:07.451698Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(HEIGHT,WIDTH,3)\n\nmodel= segnet(input_shape, NB_CLASSES, kernel=3, pool_size=(2, 2), output_mode=\"sigmoid\")\nmodel.compile(optimizer=\"adam\", loss=bce_dice_loss, metrics=[dice_coef])\nmodel.summary()","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:18:25.415627Z","iopub.status.busy":"2021-11-24T08:18:25.415321Z","iopub.status.idle":"2021-11-24T08:18:28.625459Z","shell.execute_reply":"2021-11-24T08:18:28.624622Z","shell.execute_reply.started":"2021-11-24T08:18:25.415572Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Entrainement","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\n\nmodel_info = model.fit_generator(generator=train_generator,\n                                  validation_data=valid_generator,\n                                  callbacks=[checkpoint, early_stopping, reduce_learning_rate, csv_logger],\n                                  epochs=EPOCHS)","metadata":{"execution":{"iopub.execute_input":"2021-11-23T11:17:16.783449Z","iopub.status.busy":"2021-11-23T11:17:16.783145Z","iopub.status.idle":"2021-11-23T14:43:44.492262Z","shell.execute_reply":"2021-11-23T14:43:44.490754Z","shell.execute_reply.started":"2021-11-23T11:17:16.783398Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Courbes des résultats de l'entrainement","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nplt.subplot(221)\nplt.plot(model_info.history['loss'])\nplt.plot(model_info.history['val_loss'])\nplt.title('Model loss by epoch')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\n\nplt.subplot(222)\nplt.plot(model_info.history['dice_coef'])\nplt.plot(model_info.history['val_dice_coef'])\nplt.title('Model dice_coef by epoch')\nplt.ylabel('dice_coef')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\nplt.show()\n","metadata":{"execution":{"iopub.execute_input":"2021-11-23T14:52:26.535521Z","iopub.status.busy":"2021-11-23T14:52:26.535077Z","iopub.status.idle":"2021-11-23T14:52:27.191142Z","shell.execute_reply":"2021-11-23T14:52:27.190001Z","shell.execute_reply.started":"2021-11-23T14:52:26.535468Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Chargement des poids du modèle après entrainement","metadata":{}},{"cell_type":"code","source":"output_model_path = \"./model.h5\"\n\ntry:\n    try:\n        # Si entrainement du modele, les nouveaux poids sont dans output\n        model.load_weights(output_model_path)\n        print(\"model.h5 en output chargé!\")\n    except:\n        print(\"model.h5 non entrainé en output, non chargé\")\n        try:\n            # Si modele pré entrainé en input\n            model.load_weights(input_model_path)\n            print(\"model.h5 pré entrainé chargé!\")\n        except:\n            print(\"model.h5 non pré entrainé en input, non chargé\")\n            pass\nexcept:\n    print(\"aucun model.h5 chargé\")\n    pass","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:18:48.382452Z","iopub.status.busy":"2021-11-24T08:18:48.381779Z","iopub.status.idle":"2021-11-24T08:18:51.414190Z","shell.execute_reply":"2021-11-24T08:18:51.413357Z","shell.execute_reply.started":"2021-11-24T08:18:48.382396Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resultats sur plusieurs images du set de validation","metadata":{"tags":[]}},{"cell_type":"code","source":"Test_images = val_idx[0:100]\n\ncheck_generator = DataGenerator(Test_images,\n                                df=mask_count_df,\n                                target_df=train_df,\n                                shuffle=False,\n                                reshape=(HEIGHT, WIDTH),\n                                augment=False,\n                                n_channels=CHANNELS,\n                                color_mode = COLOR_MODE,\n                                n_classes=NB_CLASSES,\n                                batch_size=1)\n\nbatch_pred_masks = model.predict_generator(check_generator, \n                                            workers=1,\n                                            verbose=1)","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:18:58.740845Z","iopub.status.busy":"2021-11-24T08:18:58.740530Z","iopub.status.idle":"2021-11-24T08:19:21.316928Z","shell.execute_reply":"2021-11-24T08:19:21.315953Z","shell.execute_reply.started":"2021-11-24T08:18:58.740783Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"THRESHOLD = 0.5 # seuil à partir duquel on considère le masque prédit à 1\n\nprint(Fore.GREEN + 'Masque original')\nprint(Fore.YELLOW + 'Masque prédit')\nprint(Fore.BLUE + 'Fit du masque prédit avec le masque original')\n\nfor i in range(10):\n    batch_pred_masks_thr = np.zeros(batch_pred_masks[i].shape).astype(np.uint8)\n    batch_pred_masks_thr[batch_pred_masks[i] > THRESHOLD] = 1\n    \n    visualize_image_mask_prediction(check_generator.__getitem__(i)[0][0,:,:,:],\n                                    check_generator.__getitem__(i)[1][0,:,:,:],\n                                    batch_pred_masks_thr,\n                                    Transparency=True)","metadata":{"execution":{"iopub.execute_input":"2021-11-24T08:20:51.007481Z","iopub.status.busy":"2021-11-24T08:20:51.007182Z","iopub.status.idle":"2021-11-24T08:20:51.851520Z","shell.execute_reply":"2021-11-24T08:20:51.848967Z","shell.execute_reply.started":"2021-11-24T08:20:51.007431Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calcul du dice moyen par classe de nuage","metadata":{"tags":[]}},{"cell_type":"code","source":"# Calcul du dice moyen/class sur les images Test\n\ndice_fish=[]\ndice_flower=[]\ndice_gravel=[]\ndice_sugar=[]\n\nfor i in range(100):\n    batch_pred_masks_thr = np.zeros(batch_pred_masks[i].shape).astype(np.uint8)\n    batch_pred_masks_thr[batch_pred_masks[i] > THRESHOLD] = 1\n    dice_fish.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[0])\n    dice_flower.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[1])\n    dice_gravel.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[2])\n    dice_sugar.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[3])\n\nprint(\"Moyen dice fish\",np.mean(dice_fish))\nprint(\"Moyen dice flower\",np.mean(dice_flower))\nprint(\"Moyen dice gravel\",np.mean(dice_gravel))\nprint(\"Moyen dice sugar\",np.mean(dice_sugar))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_log = \"./training.log\"\n\nlog=pd.read_csv(file_log)\nlog.head()\n\nplt.figure(figsize=(12,10))\nplt.subplot(221)\nplt.plot(log['loss'])\nplt.plot(log['val_loss'])\nplt.title('Model loss by epoch')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\n\nplt.subplot(222)\nplt.plot(log['dice_coef'])\nplt.plot(log['val_dice_coef'])\nplt.title('Model dice_coef by epoch')\nplt.ylabel('dice_coef')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\nplt.show()\n","metadata":{"execution":{"iopub.execute_input":"2021-11-23T15:22:21.714109Z","iopub.status.busy":"2021-11-23T15:22:21.713774Z","iopub.status.idle":"2021-11-23T15:22:22.026769Z","shell.execute_reply":"2021-11-23T15:22:22.025911Z","shell.execute_reply.started":"2021-11-23T15:22:21.714058Z"}},"execution_count":null,"outputs":[]}]}