{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models --quiet","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:48:56.385256Z","iopub.execute_input":"2021-12-01T15:48:56.385559Z","iopub.status.idle":"2021-12-01T15:49:04.37089Z","shell.execute_reply.started":"2021-12-01T15:48:56.385502Z","shell.execute_reply":"2021-12-01T15:49:04.370064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install --upgrade imgaug","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:04.374951Z","iopub.execute_input":"2021-12-01T15:49:04.375241Z","iopub.status.idle":"2021-12-01T15:49:10.643678Z","shell.execute_reply.started":"2021-12-01T15:49:04.375187Z","shell.execute_reply":"2021-12-01T15:49:10.642662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importation des modules utiles","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport albumentations as albu\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport segmentation_models as sm\nimport colorama\nfrom colorama import Fore\nfrom imgaug.augmentables.segmaps import SegmentationMapOnImage\n\nfrom tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger \nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import Sequence","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:10.646387Z","iopub.execute_input":"2021-12-01T15:49:10.646714Z","iopub.status.idle":"2021-12-01T15:49:14.517071Z","shell.execute_reply.started":"2021-12-01T15:49:10.646663Z","shell.execute_reply":"2021-12-01T15:49:14.51623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import des scripts de fonctions utiles","metadata":{}},{"cell_type":"code","source":"from clouds_graph_functions import visualize_image_mask_prediction\nfrom clouds_utilities_functions import np_resize, build_masks\nfrom clouds_utilities_functions import dice_coef, dice_loss, bce_dice_loss, dice_coef_class","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:14.518535Z","iopub.execute_input":"2021-12-01T15:49:14.518842Z","iopub.status.idle":"2021-12-01T15:49:14.642944Z","shell.execute_reply.started":"2021-12-01T15:49:14.51879Z","shell.execute_reply":"2021-12-01T15:49:14.642052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Définition du chemin des données","metadata":{}},{"cell_type":"code","source":"NUAGES_PATH = '/kaggle/input/understanding_cloud_organization/'\n\nNUAGES_TRAIN_PATH = NUAGES_PATH + 'train_images/'","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:14.646783Z","iopub.execute_input":"2021-12-01T15:49:14.647161Z","iopub.status.idle":"2021-12-01T15:49:14.653617Z","shell.execute_reply.started":"2021-12-01T15:49:14.647099Z","shell.execute_reply":"2021-12-01T15:49:14.652891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chargement du DataFrame et modification pour le DataGenerator","metadata":{}},{"cell_type":"code","source":"# Chargement du jeu de données d'entrainement\ntrain_df = pd.read_csv(NUAGES_PATH + 'train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:14.657231Z","iopub.execute_input":"2021-12-01T15:49:14.657702Z","iopub.status.idle":"2021-12-01T15:49:18.994343Z","shell.execute_reply.started":"2021-12-01T15:49:14.657524Z","shell.execute_reply":"2021-12-01T15:49:18.993567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain_df['hasMask'] = ~ train_df['EncodedPixels'].isna()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:18.995799Z","iopub.execute_input":"2021-12-01T15:49:18.996101Z","iopub.status.idle":"2021-12-01T15:49:19.03681Z","shell.execute_reply.started":"2021-12-01T15:49:18.996036Z","shell.execute_reply":"2021-12-01T15:49:19.035932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.038296Z","iopub.execute_input":"2021-12-01T15:49:19.038621Z","iopub.status.idle":"2021-12-01T15:49:19.063735Z","shell.execute_reply.started":"2021-12-01T15:49:19.038562Z","shell.execute_reply":"2021-12-01T15:49:19.062979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\nmask_count_df.sort_values('hasMask', ascending=False, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.065111Z","iopub.execute_input":"2021-12-01T15:49:19.065646Z","iopub.status.idle":"2021-12-01T15:49:19.096413Z","shell.execute_reply.started":"2021-12-01T15:49:19.065586Z","shell.execute_reply":"2021-12-01T15:49:19.095795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mask_count_df.shape)\nmask_count_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.098059Z","iopub.execute_input":"2021-12-01T15:49:19.098479Z","iopub.status.idle":"2021-12-01T15:49:19.110246Z","shell.execute_reply.started":"2021-12-01T15:49:19.098432Z","shell.execute_reply":"2021-12-01T15:49:19.109508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parametres generaux","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 6\nHEIGHT = 320\nWIDTH = 480\nCHANNELS = 3 # toujours garder 3 channels car les modèles d'initialisation des poids ont été entrainé sur des images couleurs avec 3 canaux\nCOLOR_MODE=True # True pour images couleurs et False pour images en noir et blanc\nNB_CLASSES = 4","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.111439Z","iopub.execute_input":"2021-12-01T15:49:19.111918Z","iopub.status.idle":"2021-12-01T15:49:19.116779Z","shell.execute_reply.started":"2021-12-01T15:49:19.111867Z","shell.execute_reply":"2021-12-01T15:49:19.116006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator pour image et masque","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path=NUAGES_TRAIN_PATH, batch_size=BATCH_SIZE, dim=(1400, 2100),\n                 n_channels=CHANNELS, color_mode=True,reshape=None, augment=False,\n                 n_classes=NB_CLASSES, random_state=222, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.reshape = reshape\n        self.n_channels = n_channels\n        self.color_mode = color_mode\n        self.augment = augment\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n        np.random.seed(self.random_state)\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            \n            if self.augment:\n                X, y = self.__augment_batch(X, y)\n            \n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)          \n\n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        if self.reshape is None:\n            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        else:\n            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}{im_name}\"\n            \n            if self.color_mode == True:\n                img = self.__load_rgb(img_path)\n                \n                if self.reshape is not None:\n                    img = np_resize(img, self.reshape)\n            \n            else:\n                img = self.__load_grayscale(img_path)\n                \n                if self.reshape is not None:\n                    img = np_resize(img, self.reshape)\n                \n                img = np.dstack((img,)*self.n_channels) # stack the black and white image in n channels\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n\n    def __generate_y(self, list_IDs_batch):\n        if self.reshape is None:\n            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        else:\n            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            \n            if self.reshape is not None:\n                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n            else:\n                masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n        return img\n    \n    def __random_transform(self, img, masks):\n        #augmentation random d'images\n        composition = albu.Compose([albu.HorizontalFlip(),\n                                    albu.VerticalFlip(),\n                                    albu.Rotate(limit=20),\n                                    albu.GridDistortion(),\n                                    albu.ShiftScaleRotate(rotate_limit=45, shift_limit=0.15, scale_limit=0.15)])\n        \n        composed = composition(image=img, mask=masks)\n        aug_img = composed['image']\n        aug_masks = composed['mask']\n        \n        return aug_img, aug_masks  \n    \n    def __augment_batch(self, img_batch, masks_batch):\n        # generation du batch d'augmentation de l'image et de son masque associé\n        for i in range(img_batch.shape[0]):\n            img_batch[i, ], masks_batch[i, ] = self.__random_transform(img_batch[i, ], masks_batch[i, ])\n        \n        return img_batch, masks_batch","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.118121Z","iopub.execute_input":"2021-12-01T15:49:19.118623Z","iopub.status.idle":"2021-12-01T15:49:19.154303Z","shell.execute_reply.started":"2021-12-01T15:49:19.118561Z","shell.execute_reply":"2021-12-01T15:49:19.153551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Séparation des données d'entrainement et de validation (par ID unique)","metadata":{}},{"cell_type":"code","source":"train_idx, val_idx = train_test_split(mask_count_df.index, random_state=69, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.155974Z","iopub.execute_input":"2021-12-01T15:49:19.156445Z","iopub.status.idle":"2021-12-01T15:49:19.168434Z","shell.execute_reply.started":"2021-12-01T15:49:19.156393Z","shell.execute_reply":"2021-12-01T15:49:19.167594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Création des instances de la class DataGenerator","metadata":{}},{"cell_type":"code","source":"train_generator = DataGenerator(train_idx, \n                                df=mask_count_df,\n                                target_df=train_df,\n                                batch_size=BATCH_SIZE,\n                                reshape=(HEIGHT, WIDTH),\n                                augment=True,\n                                n_channels=CHANNELS,\n                                color_mode = COLOR_MODE,\n                                n_classes=NB_CLASSES)\n\nvalid_generator = DataGenerator(val_idx, \n                                  df=mask_count_df,\n                                  target_df=train_df,\n                                  batch_size=BATCH_SIZE, \n                                  reshape=(HEIGHT, WIDTH),\n                                  augment=False,\n                                  n_channels=CHANNELS,\n                                  color_mode = COLOR_MODE,\n                                  n_classes=NB_CLASSES)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.171077Z","iopub.execute_input":"2021-12-01T15:49:19.171875Z","iopub.status.idle":"2021-12-01T15:49:19.179952Z","shell.execute_reply.started":"2021-12-01T15:49:19.171823Z","shell.execute_reply":"2021-12-01T15:49:19.179108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"# ModelCheckpoint callback : pour enregistrer les poids du modele.\ncheckpoint = ModelCheckpoint(\"./model.h5\",\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             save_weights_only=True)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               mode='min',\n                               min_delta = 0.01,\n                               patience=5,\n                               restore_best_weights=True,\n                               verbose=1)\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n                                         mode='min',\n                                         episilon = 0.01,\n                                         patience=3,\n                                         factor=0.1,\n                                         min_lr=1e-6,\n                                         verbose=1)\n\n# CSVLogger callback : pour enregistrer l'historique d'entrainement.\ncsv_logger = CSVLogger('./training.log')","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.181661Z","iopub.execute_input":"2021-12-01T15:49:19.182275Z","iopub.status.idle":"2021-12-01T15:49:19.192767Z","shell.execute_reply.started":"2021-12-01T15:49:19.181956Z","shell.execute_reply":"2021-12-01T15:49:19.191954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MODELE de segmentation","metadata":{}},{"cell_type":"code","source":"'''ATTENTION: pour le choix du modele si les images d'entrainement sont en noir et blanc,\nles modèles et les poids obtenus avec des images en couleur ne sont pas compatibles''' \n\nBACKBONE = 'resnet50'\n\nmodel = sm.FPN(BACKBONE, \n                classes=NB_CLASSES,\n                input_shape=(HEIGHT, WIDTH, CHANNELS),\n                encoder_weights='imagenet',\n                activation='sigmoid',\n                encoder_freeze=False)\n\nmodel.compile(optimizer=\"adam\", loss=bce_dice_loss, metrics=[dice_coef])","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:19.194564Z","iopub.execute_input":"2021-12-01T15:49:19.194853Z","iopub.status.idle":"2021-12-01T15:49:30.37606Z","shell.execute_reply.started":"2021-12-01T15:49:19.194804Z","shell.execute_reply":"2021-12-01T15:49:30.37534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chargement des poids du modèle pré entrainé si existant","metadata":{}},{"cell_type":"code","source":"input_model_path = \"../input/clouds-segmentation-fpn/model.h5\"\n\ntry:\n    model.load_weights(input_model_path)\n    print(\"model.h5 pré entrainé chargé!\")\nexcept:\n    print(\"model.h5 non pré entrainé, non chargé\")\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:30.377646Z","iopub.execute_input":"2021-12-01T15:49:30.377947Z","iopub.status.idle":"2021-12-01T15:49:30.384618Z","shell.execute_reply.started":"2021-12-01T15:49:30.377897Z","shell.execute_reply":"2021-12-01T15:49:30.383705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Entrainement","metadata":{}},{"cell_type":"code","source":"EPOCHS = 10\n\nmodel_info = model.fit_generator(generator=train_generator,\n                                  validation_data=valid_generator,\n                                  callbacks=[checkpoint, early_stopping, reduce_learning_rate, csv_logger],\n                                  epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T15:49:30.386032Z","iopub.execute_input":"2021-12-01T15:49:30.386541Z","iopub.status.idle":"2021-12-01T16:06:28.597273Z","shell.execute_reply.started":"2021-12-01T15:49:30.386493Z","shell.execute_reply":"2021-12-01T16:06:28.596008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Courbes des résultats de l'entrainement","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nplt.subplot(121)\nplt.plot(model_info.history['loss'])\nplt.plot(model_info.history['val_loss'])\nplt.title('Model loss by epoch')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\n\nplt.subplot(122)\nplt.plot(model_info.history['dice_coef'])\nplt.plot(model_info.history['val_dice_coef'])\nplt.title('Model dice_coef by epoch')\nplt.ylabel('dice_coef')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T16:06:28.603262Z","iopub.execute_input":"2021-12-01T16:06:28.612296Z","iopub.status.idle":"2021-12-01T16:06:29.141465Z","shell.execute_reply.started":"2021-12-01T16:06:28.612236Z","shell.execute_reply":"2021-12-01T16:06:29.140703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chargement des poids du modèle après entrainement","metadata":{}},{"cell_type":"code","source":"output_model_path = \"./model.h5\"\n\ntry:\n    try:\n        # Si entrainement du modele, les nouveaux poids sont dans output\n        model.load_weights(output_model_path)\n        print(\"model.h5 en output chargé!\")\n    except:\n        print(\"model.h5 non entrainé en output, non chargé\")\n        try:\n            # Si modele pré entrainé en input\n            model.load_weights(input_model_path)\n            print(\"model.h5 pré entrainé chargé!\")\n        except:\n            print(\"model.h5 non pré entrainé en input, non chargé\")\n            pass\nexcept:\n    print(\"aucun model.h5 chargé\")\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-12-01T16:06:29.142745Z","iopub.execute_input":"2021-12-01T16:06:29.143207Z","iopub.status.idle":"2021-12-01T16:06:29.451491Z","shell.execute_reply.started":"2021-12-01T16:06:29.143156Z","shell.execute_reply":"2021-12-01T16:06:29.450779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resultats sur plusieurs images du set de validation","metadata":{}},{"cell_type":"code","source":"Test_images = val_idx[0:100]\n\ncheck_generator = DataGenerator(Test_images,\n                                df=mask_count_df,\n                                target_df=train_df,\n                                shuffle=False,\n                                reshape=(HEIGHT, WIDTH),\n                                augment=False,\n                                n_channels=CHANNELS,\n                                color_mode = COLOR_MODE,\n                                n_classes=NB_CLASSES,\n                                batch_size=1)\n\nbatch_pred_masks = model.predict_generator(check_generator, \n                                            workers=1,\n                                            verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T16:06:29.452856Z","iopub.execute_input":"2021-12-01T16:06:29.453163Z","iopub.status.idle":"2021-12-01T16:06:44.502045Z","shell.execute_reply.started":"2021-12-01T16:06:29.453103Z","shell.execute_reply":"2021-12-01T16:06:44.501211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"THRESHOLD = 0.5 # seuil à partir duquel on considère le masque prédit à 1\n\nprint(Fore.GREEN + 'Masque original')\nprint(Fore.YELLOW + 'Masque prédit')\nprint(Fore.BLUE + 'Fit du masque prédit avec le masque original')\n\nfor i in range(5):\n    batch_pred_masks_thr = np.zeros(batch_pred_masks[i].shape).astype(np.uint8)\n    batch_pred_masks_thr[batch_pred_masks[i] > THRESHOLD] = 1\n    \n    visualize_image_mask_prediction(check_generator.__getitem__(i)[0][0,:,:,:],\n                                    check_generator.__getitem__(i)[1][0,:,:,:],\n                                    batch_pred_masks_thr,\n                                    Transparency=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T16:19:30.182805Z","iopub.execute_input":"2021-12-01T16:19:30.183135Z","iopub.status.idle":"2021-12-01T16:19:35.777881Z","shell.execute_reply.started":"2021-12-01T16:19:30.183076Z","shell.execute_reply":"2021-12-01T16:19:35.777091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calcul du dice moyen par type de nuage","metadata":{}},{"cell_type":"code","source":"# Calcul du dice moyen /class sur les images de validation\n\ndice_fish=[]\ndice_flower=[]\ndice_gravel=[]\ndice_sugar=[]\n\nfor i in range(100):\n    batch_pred_masks_thr = np.zeros(batch_pred_masks[i].shape).astype(np.uint8)\n    batch_pred_masks_thr[batch_pred_masks[i] > THRESHOLD] = 1\n    dice_fish.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[0])\n    dice_flower.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[1])\n    dice_gravel.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[2])\n    dice_sugar.append(dice_coef_class(check_generator.__getitem__(i)[1][0,:,:,:],batch_pred_masks_thr)[3])\n\nprint(\"Moyen dice fish\",np.mean(dice_fish))\nprint(\"Moyen dice flower\",np.mean(dice_flower))\nprint(\"Moyen dice gravel\",np.mean(dice_gravel))\nprint(\"Moyen dice sugar\",np.mean(dice_sugar))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T16:06:54.971395Z","iopub.execute_input":"2021-12-01T16:06:54.971816Z","iopub.status.idle":"2021-12-01T16:07:32.446554Z","shell.execute_reply.started":"2021-12-01T16:06:54.971769Z","shell.execute_reply":"2021-12-01T16:07:32.445665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_log = \"./training.log\"\n\nlog=pd.read_csv(file_log)\nlog.head()\n\nplt.figure(figsize=(12,10))\nplt.subplot(221)\nplt.plot(log['loss'])\nplt.plot(log['val_loss'])\nplt.title('Model loss by epoch')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\n\nplt.subplot(222)\nplt.plot(log['dice_coef'])\nplt.plot(log['val_dice_coef'])\nplt.title('Model dice_coef by epoch')\nplt.ylabel('dice_coef')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T16:07:32.449812Z","iopub.execute_input":"2021-12-01T16:07:32.450091Z","iopub.status.idle":"2021-12-01T16:07:32.764761Z","shell.execute_reply.started":"2021-12-01T16:07:32.450031Z","shell.execute_reply":"2021-12-01T16:07:32.764106Z"},"trusted":true},"execution_count":null,"outputs":[]}]}