{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prérequis pour faire fonctionner le modéle MASK RCNN","metadata":{}},{"cell_type":"code","source":"\n#Pour fonctionner correctement le framework Mask RCNN a besoin de la version keras==2.2.4 et tensorflow==1.14.0\n!pip uninstall keras -y\n!pip install keras==2.2.4\n#!pip uninstall tensorflow -y\n#!pip install tensorflow==1.14.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verification des versions de keras et tensorflow\n\nimport tensorflow\nimport keras\nimport skimage\n\nprint(tensorflow.__version__)\nprint(keras.__version__)\nprint(skimage.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:51:02.279951Z","iopub.execute_input":"2021-11-22T07:51:02.280355Z","iopub.status.idle":"2021-11-22T07:51:05.775958Z","shell.execute_reply.started":"2021-11-22T07:51:02.280280Z","shell.execute_reply":"2021-11-22T07:51:05.774993Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# C'est parti pour le modéle Mask RCNN!!","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n#Importation des modules utiles\n\nimport os\nimport gc\nimport sys\nimport time\nimport json\nimport glob\nimport random\nfrom pathlib import Path\nimport pandas as pd\n\nfrom PIL import Image\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom imgaug import augmenters as iaa\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:51:08.748887Z","iopub.execute_input":"2021-11-22T07:51:08.749326Z","iopub.status.idle":"2021-11-22T07:51:09.101779Z","shell.execute_reply.started":"2021-11-22T07:51:08.749254Z","shell.execute_reply":"2021-11-22T07:51:09.101013Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Chargement du DataFrame et nettoyage\n\ntrain_df = pd.read_csv(\"../input/understanding_cloud_organization/train.csv\")\ntrain_df = train_df.dropna()\ntrain_df.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-11-22T07:51:14.720579Z","iopub.execute_input":"2021-11-22T07:51:14.721180Z","iopub.status.idle":"2021-11-22T07:51:18.420112Z","shell.execute_reply.started":"2021-11-22T07:51:14.720911Z","shell.execute_reply":"2021-11-22T07:51:18.419128Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Restructuration du Dataframe","metadata":{}},{"cell_type":"code","source":"#les cellules suivantes permettent de restructurer le dataframe afin qu'il puisse alimenter le modéle  MaskRCNN. Pour chaque image , on a la liste\n#des masques au format RLE (\"EncodedPixels\" colonne) et la catégorie du nuage (\"CategoryId\" colonne)\n\ncategory_list = [\"Fish\",\"Flower\",\"Gravel\",\"Sugar\"]\n\ntrain_dict = {}\ntrain_class_dict = {}\nfor idx, row in train_df.iterrows():\n    image_filename = row.Image_Label.split(\"_\")[0]\n    class_name = row.Image_Label.split(\"_\")[1]\n    class_id = category_list.index(class_name)\n    if train_dict.get(image_filename):\n        train_dict[image_filename].append(row.EncodedPixels)\n        train_class_dict[image_filename].append(class_id)\n    else:\n        train_dict[image_filename] = [row.EncodedPixels]\n        train_class_dict[image_filename] = [class_id]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:51:23.168173Z","iopub.execute_input":"2021-11-22T07:51:23.168483Z","iopub.status.idle":"2021-11-22T07:51:25.723903Z","shell.execute_reply.started":"2021-11-22T07:51:23.168424Z","shell.execute_reply":"2021-11-22T07:51:25.722880Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(columns=[\"image_id\",\"EncodedPixels\",\"CategoryId\",\"Width\",\"Height\"])\nfor key, value in train_dict.items():\n    img = Image.open(\"../input/understanding_cloud_organization/train_images/{}\".format(key))\n    width, height = img.width, img.height\n    df = df.append({\"image_id\": key, \"EncodedPixels\": value, \"CategoryId\": train_class_dict[key], \"Width\": width, \"Height\": height},ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:51:30.628429Z","iopub.execute_input":"2021-11-22T07:51:30.628796Z","iopub.status.idle":"2021-11-22T07:53:10.900786Z","shell.execute_reply.started":"2021-11-22T07:51:30.628730Z","shell.execute_reply":"2021-11-22T07:53:10.899952Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:53:24.661977Z","iopub.execute_input":"2021-11-22T07:53:24.662329Z","iopub.status.idle":"2021-11-22T07:53:24.684728Z","shell.execute_reply.started":"2021-11-22T07:53:24.662271Z","shell.execute_reply":"2021-11-22T07:53:24.683597Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Récuperation du modéle MaskRCNN et initialisation","metadata":{}},{"cell_type":"code","source":"#Parametres généraux \n\nDATA_DIR = Path('../kaggle/input/')\nROOT_DIR = \"../working\"\n\nNUM_CATS = len(category_list) # Nombre de catégorie de nuages\nIMAGE_SIZE = 512 # taille des images sur lesquelles nous allons travailler 512*512 au lieu de 2100 * 1400","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:53:27.703034Z","iopub.execute_input":"2021-11-22T07:53:27.703438Z","iopub.status.idle":"2021-11-22T07:53:27.708929Z","shell.execute_reply.started":"2021-11-22T07:53:27.703380Z","shell.execute_reply":"2021-11-22T07:53:27.707671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Chargement du framework modéle Mask RCNN depuis  git\n!git clone https://www.github.com/matterport/Mask_RCNN.git\nos.chdir('Mask_RCNN')\n\n!rm -rf .git\n!rm -rf images assets","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:53:30.259631Z","iopub.execute_input":"2021-11-22T07:53:30.260132Z","iopub.status.idle":"2021-11-22T07:53:41.382446Z","shell.execute_reply.started":"2021-11-22T07:53:30.260032Z","shell.execute_reply":"2021-11-22T07:53:41.381307Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Import des fonctions utiles du Framework Mask RCNN\n\nsys.path.append(ROOT_DIR+'/Mask_RCNN')\nfrom mrcnn.config import Config\n\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log\n\n#Fonction pour resizer les images  :\n\ndef resize_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)  \n    return img\n\ndef refine_masks(masks, rois):\n    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n    mask_index = np.argsort(areas)\n    union_mask = np.zeros(masks.shape[:-1], dtype=bool)\n    for m in mask_index:\n        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n        union_mask = np.logical_or(masks[:, :, m], union_mask)\n    for m in range(masks.shape[-1]):\n        mask_pos = np.where(masks[:, :, m]==True)\n        if np.any(mask_pos):\n            y1, x1 = np.min(mask_pos, axis=1)\n            y2, x2 = np.max(mask_pos, axis=1)\n            rois[m, :] = [y1, x1, y2, x2]\n    return masks, rois\n\n\n#Fonction utile pour calculer le DICE sur chaque image testée :\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    \n    if y_true.shape[-1] == 0 or y_pred.shape[-1] == 0:\n        return 0\n    # flatten masks and compute their areas\n    y_true_f = np.reshape(y_true > .5, (-1, y_true.shape[-1])).astype(np.float32)\n    y_pred_f = np.reshape(y_pred  > .5, (-1, y_pred.shape[-1])).astype(np.float32)\n    area1 = np.sum(y_true_f, axis=0)\n    area2 = np.sum(y_pred_f, axis=0)\n    \n    intersections = np.dot(y_true_f.T, y_pred_f)\n    \n    dice= (2. * intersections + smooth) / (area1[:, None]+area2[None, :]+ smooth)\n   \n    \n    return np.mean(dice.max(axis=1))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T08:55:06.470116Z","iopub.execute_input":"2021-11-22T08:55:06.470469Z","iopub.status.idle":"2021-11-22T08:55:06.491721Z","shell.execute_reply.started":"2021-11-22T08:55:06.470405Z","shell.execute_reply":"2021-11-22T08:55:06.490521Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#Récupération des poids COCO pré-entrainés sur le modéle Mask RCNN\n!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n!ls -lh mask_rcnn_coco.h5\n\nCOCO_WEIGHTS_PATH = 'mask_rcnn_coco.h5'","metadata":{"execution":{"iopub.status.busy":"2021-11-22T08:55:10.705166Z","iopub.execute_input":"2021-11-22T08:55:10.705561Z","iopub.status.idle":"2021-11-22T08:55:17.177170Z","shell.execute_reply.started":"2021-11-22T08:55:10.705467Z","shell.execute_reply":"2021-11-22T08:55:17.175577Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#Fichier de Configuration du modéle Mask RCNN qui sera utilisé pour le mode Training et Inférence\n\nclass CloudConfig(Config):\n    NAME = \"cloud\"\n    NUM_CLASSES = NUM_CATS + 1 # nb de type de nuage + background\n    \n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1 \n    \n    BACKBONE = 'resnet50'\n    \n    IMAGE_MIN_DIM = IMAGE_SIZE\n    IMAGE_MAX_DIM = IMAGE_SIZE    \n    IMAGE_RESIZE_MODE = 'none'\n    \n    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n    \n    STEPS_PER_EPOCH = int(0.8*len(df))\n    VALIDATION_STEPS = int(0.2*len(df))\n    RPN_NMS_THRESHOLD=0.6\n    DETECTION_MAX_INSTANCES=4\n    \nconfig = CloudConfig()\nconfig.display()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:07:10.625423Z","iopub.execute_input":"2021-11-22T09:07:10.628709Z","iopub.status.idle":"2021-11-22T09:07:10.662560Z","shell.execute_reply.started":"2021-11-22T09:07:10.628639Z","shell.execute_reply":"2021-11-22T09:07:10.661480Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# Péparation du Dataset pour le Mask RCNN contenant les images , masques et labels","metadata":{}},{"cell_type":"code","source":"\n#Utilisation de la class utils.Dataset du framework pour creer notre dataset de training er validation\n#on surcharge les fonctions load_imag, load_mask qui viendront récuperer les images et les masks+labels des images\n\nclass CloudDataset(utils.Dataset):\n\n    def __init__(self, df):\n        super().__init__(self)\n        \n        # Add classes\n        for i, name in enumerate(category_list):\n            self.add_class(\"cloud\", i+1, name)\n        \n        # Add images \n        for i, row in df.iterrows():\n            self.add_image(\"cloud\", \n                           image_id=row.name, \n                           path='../../input/understanding_cloud_organization/train_images/'+str(row.image_id), \n                           labels=row['CategoryId'],\n                           annotations=row['EncodedPixels'], \n                           height=row['Height'], width=row['Width'])\n\n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path'], [category_list[int(x)] for x in info['labels']]\n    \n    def load_image(self, image_id):\n        return resize_image(self.image_info[image_id]['path'])\n\n    def load_mask(self, image_id):\n        info = self.image_info[image_id]\n                \n        mask = np.zeros((IMAGE_SIZE, IMAGE_SIZE, len(info['annotations'])), dtype=np.uint8)\n        labels = []\n        \n        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):\n            sub_mask = np.full(info['height']*info['width'], 0, dtype=np.uint8)\n            annotation = [int(x) for x in annotation.split(' ')]\n            \n            for i, start_pixel in enumerate(annotation[::2]):\n                sub_mask[start_pixel: start_pixel+annotation[2*i+1]] = 1\n\n            sub_mask = sub_mask.reshape((info['height'], info['width']), order='F')\n            sub_mask = cv2.resize(sub_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n            \n            mask[:, :, m] = sub_mask\n            labels.append(int(label)+1)\n            \n        return mask, np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T08:55:40.695414Z","iopub.execute_input":"2021-11-22T08:55:40.695730Z","iopub.status.idle":"2021-11-22T08:55:40.714086Z","shell.execute_reply.started":"2021-11-22T08:55:40.695671Z","shell.execute_reply":"2021-11-22T08:55:40.713044Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Séparation des données d'entrainement et de validation (par ID unique)","metadata":{}},{"cell_type":"code","source":"#Creation du Dataset de Training  et de Validation. Split 80% /20%\n\ntraining_percentage = 0.8\n\ntraining_set_size = int(training_percentage*len(df))\nvalidation_set_size = int((1-training_percentage)*len(df))\n#training_set_size = 100\n#validation_set_size = 1000\n\n\ntrain_dataset = CloudDataset(df[:training_set_size])\ntrain_dataset.prepare()\n\nvalid_dataset = CloudDataset(df[training_set_size:training_set_size+validation_set_size])\nvalid_dataset.prepare()\n\n#Affichage de 5 images du dataset de training avec les masks\n\nfor i in range(5):\n    image_id = i\n    print(train_dataset.image_reference(image_id))\n    \n    image = train_dataset.load_image(image_id)\n    mask, class_ids = train_dataset.load_mask(image_id)\n    visualize.display_top_masks(image, mask, class_ids, train_dataset.class_names, limit=4)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T08:22:16.888715Z","iopub.execute_input":"2021-11-22T08:22:16.889143Z","iopub.status.idle":"2021-11-22T08:22:20.400141Z","shell.execute_reply.started":"2021-11-22T08:22:16.889070Z","shell.execute_reply":"2021-11-22T08:22:20.399149Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Entrainement du modéle MASK RCNN","metadata":{}},{"cell_type":"markdown","source":"# Callbacks","metadata":{}},{"cell_type":"code","source":"#Création d'un callback MeanAverageDice qui ira calculer à la fin de chaque epcohs , le dice moyen  sur les données de validation\n\nimport keras\nfrom mrcnn.model import *\nfrom keras.callbacks import Callback\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau \n\n\n\nclass MeanAverageDice(Callback):\n    def __init__(self, train_model: MaskRCNN, inference_model: MaskRCNN, dataset: CloudDataset,\n                 calculate_dice_at_every_X_epoch=1, dataset_limit=99,\n                 verbose=1):\n        super().__init__()\n        self.train_model = train_model\n        self.inference_model = inference_model\n        self.dataset = dataset\n        self.calculate_dice_at_every_X_epoch = calculate_dice_at_every_X_epoch\n        self.dataset_limit = len(self.dataset.image_ids)\n        if dataset_limit is not None:\n            self.dataset_limit = dataset_limit\n        self.dataset_image_ids = self.dataset.image_ids.copy()\n\n        if inference_model.config.BATCH_SIZE != 1:\n            raise ValueError(\"This callback only works with the bacth size of 1\")\n\n        self._verbose_print = print if verbose > 0 else lambda *a, **k: None\n\n    def on_epoch_end(self, epoch, logs=None):\n\n        self._verbose_print(\"Dice moyen sur détection\")\n        self._load_weights_for_model()\n\n        dices = self._calculate_mean_average_dice()\n        dice_mean = np.mean(dices)\n\n        logs[\"val_mean_dice\"] = dice_mean\n\n        self._verbose_print(\"Dice moyen sur detection a l' epoch {0} is: {1}\".format(epoch+1,dice_mean))\n\n        super().on_epoch_end(epoch, logs)\n\n    def _load_weights_for_model(self):\n        last_weights_path = self.train_model.find_last()\n        self._verbose_print(\"Loaded weights for the inference model (last checkpoint of the train model): {0}\".format(\n            last_weights_path))\n        self.inference_model.load_weights(last_weights_path,\n                                          by_name=True)\n\n    def _calculate_mean_average_dice(self):\n        mAPs = []\n\n        # random subset sur les données\n        np.random.shuffle(self.dataset_image_ids)\n\n        for image_id in self.dataset_image_ids[:self.dataset_limit]:\n            image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(self.dataset, self.inference_model.config,\n                                                                             image_id, use_mini_mask=False)\n            molded_images = np.expand_dims(mold_image(image, self.inference_model.config), 0)\n            results = self.inference_model.detect(molded_images, verbose=0)\n            r = results[0]\n            # Compute dice - VOC uses IoU 0.5\n            dice_moyen=dice_coef(gt_mask.astype(np.float32),r['masks'].astype(np.float32))\n\n            mAPs.append(dice_moyen)\n                \n\n        return np.array(mAPs)\n\n\n\n#initialisation du callback MeanAverageDice\nmean_average_dice_callback = MeanAverageDice(model,\nmodel_inference, valid_dataset, calculate_dice_at_every_X_epoch=1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:20:30.428860Z","iopub.execute_input":"2021-11-22T09:20:30.429219Z","iopub.status.idle":"2021-11-22T09:20:30.448880Z","shell.execute_reply.started":"2021-11-22T09:20:30.429158Z","shell.execute_reply":"2021-11-22T09:20:30.447246Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#Initialisation du callback  ReduceLROnPlateau\nreduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n                                         mode='min',\n                                         episilon = 0.01,\n                                         patience=3,\n                                         factor=0.1,\n                                         min_lr=1e-6,\n                                         verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:20:49.908260Z","iopub.execute_input":"2021-11-22T09:20:49.908716Z","iopub.status.idle":"2021-11-22T09:20:49.915874Z","shell.execute_reply.started":"2021-11-22T09:20:49.908595Z","shell.execute_reply":"2021-11-22T09:20:49.914173Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"#Création de 2 instances  Mask RCNN , l'une pour l'entrainement ( training mode) , l'autre pour la détéction (inférence mode)\n\nmodel = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n\nmodel_inference = modellib.MaskRCNN(mode='inference', config=config, model_dir=ROOT_DIR)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:00:46.727589Z","iopub.execute_input":"2021-11-22T09:00:46.727968Z","iopub.status.idle":"2021-11-22T09:00:53.788951Z","shell.execute_reply.started":"2021-11-22T09:00:46.727896Z","shell.execute_reply":"2021-11-22T09:00:53.788006Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#Chargement des poids\n\n\ntry:\n    #initialisation du modéle pré-entrainé si existant\n    model.load_weights('../../input/mask-rcnn-v2/mask_rcnn_cloud_0005-2.h5', by_name=True)\n    print(\"mask_rcnn_cloud_0005-2.h5 loaded\")\nexcept:\n    \n    #initialisation du modéle d'entrainement avec les poids COCO\n    model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    'mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])\n    print(\"mask rcnn coco loaded\")\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:01:30.393638Z","iopub.execute_input":"2021-11-22T09:01:30.394044Z","iopub.status.idle":"2021-11-22T09:01:32.003884Z","shell.execute_reply.started":"2021-11-22T09:01:30.393943Z","shell.execute_reply":"2021-11-22T09:01:32.002738Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#Paramétres pour l'entrainement :Learning rate , nb d'epochs et augmentation lors de la génération d'image\n\nLR = 1e-4\nEPOCHS = 10\n\n\n# Pour appliquer de l'augmentation aux images et masks lors de la génération des batchs\n\naugmentation = iaa.Sequential([\n    iaa.Fliplr(0.5),\n    iaa.Flipud(0.5)\n], random_order=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:05:05.787062Z","iopub.execute_input":"2021-11-22T09:05:05.787409Z","iopub.status.idle":"2021-11-22T09:05:05.795490Z","shell.execute_reply.started":"2021-11-22T09:05:05.787346Z","shell.execute_reply":"2021-11-22T09:05:05.794234Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#Entrainement du modéle Mask RCNN sur le Dataset d'entrainement avec augmentation=augmentation et custom_callbacks=[mean_average_dice_callback,reduce_learning_rate]\n#La taille des batchs est de 1\n#On entraine le modéle sur toutes les couches layers='all'\n\nmodel.train(train_dataset, valid_dataset,\n            learning_rate=LR,\n            epochs=EPOCHS,\n            layers='all',\n            augmentation=augmentation,custom_callbacks=[mean_average_dice_callback,reduce_learning_rate])\n\nhistory = model.keras_model.history.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"#Affichage des graphiques\n\nplt.figure(figsize=(12,4))\nplt.subplot(121)\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('Model loss by epoch')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='right')\nplt.subplot(122)\nplt.plot(history['val_mean_dice'])\nplt.title('Model val_mean_dice by epoch')\nplt.ylabel('val_mean_dice')\nplt.xlabel('epoch')\nplt.legend(['valid'], loc='right')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chargement des poids entrainés et visualisation","metadata":{}},{"cell_type":"code","source":"#Création d'une instance Mask RCNN en mode inférence\n\nclass InferenceConfig(CloudConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    DETECTION_MIN_CONFIDENCE = 0.6\n    DETECTION_NMS_THRESHOLD = 0.3\n    RPN_ANCHOR_SCALES = (16,64, 96, 128, 256)\n    DETECTION_MAX_INSTANCES=4\n    \n\ninference_config = InferenceConfig()\n\nmodel_detect = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=ROOT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:57:37.461319Z","iopub.execute_input":"2021-11-22T07:57:37.461711Z","iopub.status.idle":"2021-11-22T07:57:40.852144Z","shell.execute_reply.started":"2021-11-22T07:57:37.461650Z","shell.execute_reply":"2021-11-22T07:57:40.851049Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Chargement des poids pré-entrainés\n\nmodel_detect.load_weights('../../input/mask-rcnn-v2/mask_rcnn_cloud_0005-2.h5', by_name=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T07:57:44.660966Z","iopub.execute_input":"2021-11-22T07:57:44.661373Z","iopub.status.idle":"2021-11-22T07:57:54.652436Z","shell.execute_reply.started":"2021-11-22T07:57:44.661312Z","shell.execute_reply":"2021-11-22T07:57:54.651385Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Affichage des prédictions et masks originaux +dice par image testée sur 20 images du jeux de validation\n\n\nfor i in range(1,20, 1):\n    image_id = df[\"image_id\"][i+training_set_size]\n    image_path = str('../../input/understanding_cloud_organization/train_images/'+image_id)\n    print(image_path)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    result = model_detect.detect([resize_image(image_path)])\n    r = result[0]\n    \n    if r['masks'].size > 0:\n        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n        for m in range(r['masks'].shape[-1]):\n            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n        \n        y_scale = img.shape[0]/IMAGE_SIZE\n        x_scale = img.shape[1]/IMAGE_SIZE\n        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n        \n        masks, rois = refine_masks(masks, rois)\n    else:\n        masks, rois = r['masks'], r['rois']\n        \n    visualize.display_instances(img, rois, masks, r['class_ids'], \n                                ['bg']+category_list, r['scores'],\n                                title=image_id, figsize=(12, 12))\n    print(valid_dataset.image_reference(i))\n    image = valid_dataset.load_image(i)\n    mask, class_ids = valid_dataset.load_mask(i)\n    visualize.display_top_masks(image, mask, class_ids, valid_dataset.class_names, limit=5)\n    \n    #Affichage  du dice\n    dice=dice_coef(mask.astype(np.float32),r['masks'].astype(np.float32))\n    print(\"dice:\",dice)\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T09:10:34.444974Z","iopub.execute_input":"2021-11-22T09:10:34.445366Z","iopub.status.idle":"2021-11-22T09:11:01.250466Z","shell.execute_reply.started":"2021-11-22T09:10:34.445303Z","shell.execute_reply":"2021-11-22T09:11:01.248092Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#calcul du dice moyen sur 500 images du jeux de validation\n\ndice_moyen=[]\n\nfor i in range(1,500, 1):\n    image_id = df[\"image_id\"][i+training_set_size]\n    image_path = str('../../input/understanding_cloud_organization/train_images/'+image_id)\n    #print(image_path)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    result = model_detect.detect([resize_image(image_path)])\n    r = result[0]\n    \n    if r['masks'].size > 0:\n        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n        for m in range(r['masks'].shape[-1]):\n            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n        \n        y_scale = img.shape[0]/IMAGE_SIZE\n        x_scale = img.shape[1]/IMAGE_SIZE\n        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n        \n        masks, rois = refine_masks(masks, rois)\n    else:\n        masks, rois = r['masks'], r['rois']\n        \n\n    #print(valid_dataset.image_reference(i))\n    image = valid_dataset.load_image(i)\n    mask, class_ids = valid_dataset.load_mask(i)\n    \n    #Affichage  du dice\n    dice=dice_coef(mask.astype(np.float32),r['masks'].astype(np.float32))\n    #print(\"dice:\",dice)\n    if dice>0:\n        dice_moyen.append(dice)\n\nprint(\"Dice moyen sur les images de validation-sur détéction uniquement -:\",np.mean(dice_moyen))\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T08:34:11.307614Z","iopub.execute_input":"2021-11-22T08:34:11.307994Z","iopub.status.idle":"2021-11-22T08:36:47.385462Z","shell.execute_reply.started":"2021-11-22T08:34:11.307899Z","shell.execute_reply":"2021-11-22T08:36:47.384192Z"},"trusted":true},"execution_count":36,"outputs":[]}]}